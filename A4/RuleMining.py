import pandas as pd

#%%
# Input:  D - dataset
#         Ck - candidate itemset of size k
#         min_sup - the minimum support (float between 0-1)
# Output: L - an array containing the tuples satisfying min_sup
#         all_support_data - a dictionary containing all tuples 
#                            and their assoc. support
def scanD(D, Ck, min_sup):
    # Creates a dictionary of tuples and their num of occurences
    can_dict = {}
    for tuple_t in D:
        for candidate in Ck:
            if candidate.issubset(tuple_t):
                if not candidate in can_dict: 
                    can_dict[candidate]=1 #add the candidate and set count to 1
                else: 
                    can_dict[candidate] += 1 #increase the count by 1
    # Keeps only those tuples which satisfy the minsup in L
    num_items = float(len(D))
    L = []
    all_support_data = {}
    for key in can_dict:
        support_count = can_dict[key]
        support = support_count/num_items
        if support >= min_sup:
            #append to the beginning of the list if minsup is satisfied
            L.insert(0,key)
        all_support_data[key] = support
    return L, all_support_data
#%% Creates Ck+1 given Lk
# Input: Lk - frequent itemset of size k
#        k  - the size of the frequent itemsets desired
# Output: Ck+1 - the next candidate itemset of size k+1
def generateNextCk(Lk, k): 
    next_Ck = []
    lenLk = len(Lk)
    # compare every item in Lk to itself
    for i in range(lenLk):
        for j in range(i+1, lenLk): 
            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]
            L1.sort(); L2.sort()
            if L1==L2: #if the first k-2 elements are equal,
                next_Ck.append(Lk[i] | Lk[j]) #append the union
    return next_Ck

#%%
# Input: data_set - a dataset
#        min_sup  - the minimum support (float between 0-1)
# Output: L - an array containing the tuples satisfying min_sup
#         L_support_data - a dictionary containing all tuples 
#                            and their assoc. support
def apriori(data_set, min_sup):
    # Make C1, the first set of candidate itemsets
    C1 = []
    for tuple_t in data_set:
        for item in tuple_t:
            if not [item] in C1:
                C1.append([item])
    #sort the tuples in C1
    C1.sort()
    C1 = list(map(frozenset, C1))
    
    # Converts the data set to an array of lists
    D = list(map(set, data_set))
    L1, L_support_data = scanD(D, C1, min_sup)
    #Create array for L, with L1 as first element
    L = [L1]
    k = 2
    while (len(L[k-2]) > 0):
        Ck = generateNextCk(L[k-2], k)
        Lk, support_K = scanD(D, Ck, min_sup)
        L_support_data.update(support_K)
        L.append(Lk)
        k = k + 1
    return L, L_support_data

#%% Generates an array of supports for the associated rules
def supportData(L_support_data, rules):
    supports = []
    for rule in rules:
        r = list(rule[0]) + list(rule[1])
        r.sort()
        for supp in L_support_data:
            s = list(supp)
            s.sort()
            if s == r:
                supports.append(L_support_data[supp])
    return supports
#%% Generates association rules
# Input: L - tuples satisfying the minimum support, generated by scanD
#        L_support_data - dictionary of support data generated by scanD
#        min_conf - the minimum confidence
# Output: rules - the association rules for the chosen minimum confidence threshold
def generateRules(L, L_support_data, min_conf):
    rules = []
    for i in range(1, len(L)): #only get the sets with more than 1 item
        for freqSet in L[i]:
            #Generates an array of the individual elements in the freqset
            H1 = [frozenset([item]) for item in freqSet]
            if (i > 1):
                rulesFromConseq(freqSet, H1, L_support_data, rules, min_conf)
            else:
                calculateConfidence(freqSet, H1, L_support_data, rules, min_conf)
    return rules
#%% Calculates the confidence
def calculateConfidence(freqSet, H, support_data, brl, min_conf):
    prunedH = [] #create new list to return
    for conseq in H:
        #calculate the confidence
        conf = support_data[freqSet]/support_data[freqSet-conseq]
        if conf >= min_conf: 
            brl.append((freqSet-conseq, conseq, conf))
            prunedH.append(conseq)
    return prunedH
#%% 
def rulesFromConseq(freqSet, H, support_data, brl, min_conf):
    m = len(H[0])
    if (len(freqSet) > (m + 1)): #try further merging
        Ck = generateNextCk(H, m+1)# generate new candidates
        Ck = calculateConfidence(freqSet, Ck, support_data, brl, min_conf)
        if (len(Ck) > 1):
            rulesFromConseq(freqSet, Ck, support_data, brl, min_conf)    
#%%
#load in data
df = pd.read_csv('Play_Tennis_Data_Set.csv', sep=',')

min_sup = float(input("\nPlease select the minimum support rate (0.00-1.00): "))
min_conf = float(input("Please select the minimum confidence rate (0.00-1.00): "))

#%% 
raw_records = []
for i in range(0, 14):
    raw_records.append([str(df.values[i,j]) for j in range(0,5)])
    
header = pd.read_csv('Play_Tennis_Data_Set.csv', nrows=1).columns
records = []
for record in raw_records:
    temp_record = []
    for i in range(0, 5):
        item = record[i]
        temp_record.append(header[i] + "=" + item)
    records.append(temp_record)

L, suppData = apriori(records, min_sup)
rules = generateRules(L, suppData, min_conf)
s = supportData(suppData, rules)

#Write the rules to a text file
with open("Rules.txt", 'a') as f:
    f.write("1. User Input: \n\nSupport=%.2lf\n" %min_sup)
    f.write("Confidence=%.2lf\n" %min_conf)
    f.write("\n2. Rules:\n")
    i=1
    for rule in rules:
        f.write(("\nRule %d: " %i).rstrip('\n'))
        f.write(str(list(rule[0])))
        f.write((" => "))
        f.write(str(list(rule[1])))
        f.write('\n')
        f.write('(Support=%.2lf ' %s[i-1])
        f.write('Confidence=%.2lf)\n' %rule[2])
        i = i + 1
    f.write('\n')
    f.close()